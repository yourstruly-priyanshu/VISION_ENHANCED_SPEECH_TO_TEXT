{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDONZ7JldZ8Y",
        "outputId": "315abb37-ceb7-4e2d-f805-8dfbcea3eef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install opencv-python\n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkH3xc7qhzoK",
        "outputId": "022fb56d-0a13-4010-ac6a-605b49c6db2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_dataset_paths(video_dir: str, align_dir: str):\n",
        "\n",
        "    pairs = []\n",
        "    # List all video files\n",
        "    for fname in sorted(os.listdir(video_dir)):\n",
        "        if fname.lower().endswith('.mpg'):\n",
        "            video_path = os.path.join(video_dir, fname)\n",
        "            # Construct corresponding .align filename\n",
        "            align_fname = os.path.splitext(fname)[0] + '.align'\n",
        "            align_path = os.path.join(align_dir, align_fname)\n",
        "            if os.path.isfile(align_path):\n",
        "                pairs.append((video_path, align_path))\n",
        "            else:\n",
        "                print(f\"[Warning] No alignment file found for {video_path}\")\n",
        "    return pairs\n",
        "\n",
        "VIDEO_DIR = \"/content/drive/MyDrive/data/s1\"\n",
        "ALIGN_DIR = \"/content/drive/MyDrive/data/alignments/s1\"\n",
        "\n",
        "dataset_pairs = get_dataset_paths(VIDEO_DIR, ALIGN_DIR)\n",
        "for vid_path, aln_path in dataset_pairs[:5]:\n",
        "    print(\"Video:\", vid_path)\n",
        "    print(\"Align:\", aln_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWpw9W65lGU4",
        "outputId": "86aecc04-d553-429b-e3dc-b6f9ed9d23ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video: /content/drive/MyDrive/data/s1/bbaf2n.mpg\n",
            "Align: /content/drive/MyDrive/data/alignments/s1/bbaf2n.align\n",
            "Video: /content/drive/MyDrive/data/s1/bbaf3s.mpg\n",
            "Align: /content/drive/MyDrive/data/alignments/s1/bbaf3s.align\n",
            "Video: /content/drive/MyDrive/data/s1/bbaf4p.mpg\n",
            "Align: /content/drive/MyDrive/data/alignments/s1/bbaf4p.align\n",
            "Video: /content/drive/MyDrive/data/s1/bbaf5a.mpg\n",
            "Align: /content/drive/MyDrive/data/alignments/s1/bbaf5a.align\n",
            "Video: /content/drive/MyDrive/data/s1/bbal6n.mpg\n",
            "Align: /content/drive/MyDrive/data/alignments/s1/bbal6n.align\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, cv2, torch, numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "CHAR2IDX = {ch: i+2 for i,ch in enumerate(\"abcdefghijklmnopqrstuvwxyz\")}\n",
        "CHAR2IDX[' '] = 1\n",
        "\n",
        "class LipreadingDataset(Dataset):\n",
        "    def __init__(self, video_dir, align_dir, transform=None):\n",
        "        self.video_dir = video_dir\n",
        "        self.align_dir = align_dir\n",
        "        self.transform = transform\n",
        "        self.video_files = sorted([f for f in os.listdir(video_dir) if f.endswith('.mpg')])\n",
        "    def __len__(self):\n",
        "        return len(self.video_files)\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = os.path.join(self.video_dir, self.video_files[idx])\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frames = []\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret: break\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            if self.transform:\n",
        "                frame = self.transform(frame)\n",
        "            else:\n",
        "                frame = cv2.resize(frame, (112, 112))\n",
        "                frame = torch.from_numpy(frame).permute(2,0,1).float() / 255.0\n",
        "            frames.append(frame)\n",
        "        cap.release()\n",
        "        video_tensor = torch.stack(frames).permute(1,0,2,3)\n",
        "        base = os.path.splitext(self.video_files[idx])[0]\n",
        "        align_path = os.path.join(self.align_dir, base + '.align')\n",
        "        with open(align_path, 'r') as f:\n",
        "            lines = [line.strip().split() for line in f if line.strip()]\n",
        "        words = [parts[-1] for parts in lines if len(parts) >= 3]\n",
        "        transcript = \" \".join(words).lower()\n",
        "        transcript = re.sub(r'[^a-z ]', '', transcript)\n",
        "        target_seq = [CHAR2IDX[ch] for ch in transcript if ch in CHAR2IDX]\n",
        "        target_seq = torch.tensor(target_seq, dtype=torch.long)\n",
        "        return video_tensor, target_seq\n",
        "\n",
        "def collate_fn(batch):\n",
        "    videos, targets = zip(*batch)\n",
        "    batch_size = len(videos)\n",
        "    C, H, W = videos[0].shape[0], videos[0].shape[2], videos[0].shape[3]\n",
        "    max_T = max(v.shape[1] for v in videos)\n",
        "    padded_videos = torch.zeros(batch_size, C, max_T, H, W)\n",
        "    input_lengths = []\n",
        "    for i, v in enumerate(videos):\n",
        "        T = v.shape[1]\n",
        "        padded_videos[i, :, :T, :, :] = v\n",
        "        input_lengths.append(T)\n",
        "    max_S = max(t.shape[0] for t in targets)\n",
        "    padded_targets = torch.zeros(batch_size, max_S, dtype=torch.long)\n",
        "    target_lengths = []\n",
        "    for i, t in enumerate(targets):\n",
        "        L = t.shape[0]\n",
        "        padded_targets[i, :L] = t\n",
        "        target_lengths.append(L)\n",
        "    return padded_videos, padded_targets, torch.tensor(input_lengths), torch.tensor(target_lengths)\n",
        "\n",
        "transform = None\n",
        "train_dataset = LipreadingDataset(\"/content/drive/MyDrive/data/s1\", \"/content/drive/MyDrive/data/alignments/s1\", transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, collate_fn=collate_fn, shuffle=True)\n",
        "\n",
        "for batch_idx, (videos, targets, input_lens, target_lens) in enumerate(train_loader):\n",
        "    print(f\"Batch {batch_idx}\")\n",
        "    print(f\"videos.shape      = {videos.shape}\")\n",
        "    print(f\"targets.shape     = {targets.shape}\")\n",
        "    print(f\"input_lengths     = {input_lens.tolist()}\")\n",
        "    print(f\"target_lengths    = {target_lens.tolist()}\")\n",
        "    inv = {v:k for k,v in CHAR2IDX.items()}\n",
        "    seq = targets[0, :target_lens[0]].tolist()\n",
        "    decoded = \"\".join(inv[idx] for idx in seq)\n",
        "    print(f\"sample[0] transcript = \\\"{decoded}\\\"\")\n",
        "    break"
      ],
      "metadata": {
        "id": "YZc4neKFiAx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3519452-6cbf-400b-a8af-fe391af05e59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0\n",
            "videos.shape      = torch.Size([8, 3, 75, 112, 112])\n",
            "targets.shape     = torch.Size([8, 35])\n",
            "input_lengths     = [75, 75, 75, 75, 75, 75, 75, 75]\n",
            "target_lengths    = [33, 34, 35, 33, 30, 32, 33, 30]\n",
            "sample[0] transcript = \"sil set green in v two please sil\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models.video as video_models\n",
        "\n",
        "class LipreadingModel(nn.Module):\n",
        "    def __init__(self, num_classes=28, cnn_pretrained=True, d_model=256, nhead=8, num_layers=4):\n",
        "        super().__init__()\n",
        "\n",
        "        backbone = video_models.r3d_18(pretrained=cnn_pretrained)\n",
        "\n",
        "        self.cnn = nn.Sequential(*list(backbone.children())[:-2])\n",
        "\n",
        "        self.feature_dim = 512\n",
        "\n",
        "        self.max_len = 200\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, self.max_len, self.feature_dim))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.feature_dim,\n",
        "                                                   nhead=nhead,\n",
        "                                                   dim_feedforward=self.feature_dim*4,\n",
        "                                                   activation='relu',\n",
        "                                                   batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.fc = nn.Linear(self.feature_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        B, C, T, H, W = x.shape\n",
        "\n",
        "        feat = self.cnn(x)\n",
        "\n",
        "        feat = feat.mean(dim=[3,4])\n",
        "        feat = feat.permute(0,2,1)\n",
        "\n",
        "        seq_len = feat.size(1)\n",
        "        feat = feat + self.pos_embed[:, :seq_len, :]\n",
        "\n",
        "        feat = self.transformer(feat)\n",
        "\n",
        "        logits = self.fc(feat)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        return log_probs\n",
        "\n",
        "model = LipreadingModel(num_classes=28, cnn_pretrained=True, d_model=512, nhead=8, num_layers=4)\n"
      ],
      "metadata": {
        "id": "AkFcz762i6Zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf52c527-7743-4476-ac4b-806618194f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_8r0-fI3IvP",
        "outputId": "b4d63a34-4a56-4ef1-8760-9b6f394b171f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (1.15.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IMj_D753NDX",
        "outputId": "008e4535-d0a9-43b5-bc8d-0415333d2e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'libfluidsynth1' has no installation candidate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU6iIpvT3RoK",
        "outputId": "aca04ef2-5807-42e0-8e98-fe66823d9ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 126101 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.4) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting libarchive\n",
            "  Downloading libarchive-0.4.7.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nose (from libarchive)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: libarchive\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libarchive: filename=libarchive-0.4.7-py3-none-any.whl size=31629 sha256=a8ca59201cc2ce33170a13c08d39709cc8cb0ea9e522537d33fd0a4b61ceff6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/98/bd/4893d6923dd027f455b250367d402bfd69a6f4416581df46db\n",
            "Successfully built libarchive\n",
            "Installing collected packages: nose, libarchive\n",
            "Successfully installed libarchive-0.4.7 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK-sNzXn3waR",
        "outputId": "a0450884-8ca1-4a9a-84ce-73ba7744b297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot) (3.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRRz55CE32UZ",
        "outputId": "7526079a-e8c1-4ba3-99d7-db88f563f7e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.10.0)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.1.0)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from cartopy) (24.2)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (2.9.0.post0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3.1->cartopy) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.17.0)\n",
            "Downloading Cartopy-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cartopy\n",
            "Successfully installed cartopy-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0b2NwZ9F4wP",
        "outputId": "063c1b80-87eb-4542-c6a1-48b80e4196b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, cv2, torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models.video as video_models\n",
        "from jiwer import wer\n",
        "\n",
        "VIDEO_DIR     = \"/content/drive/MyDrive/data/s1\"\n",
        "ALIGN_DIR     = \"/content/drive/MyDrive/data/alignments/s1\"\n",
        "NUM_EPOCHS    = 50\n",
        "LEARNING_RATE = 1e-5\n",
        "BATCH_SIZE    = 4\n",
        "DEVICE        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "CHARS     = [' '] + list(\"abcdefghijklmnopqrstuvwxyz\")\n",
        "CHAR2IDX  = {ch:i for i,ch in enumerate(CHARS)}\n",
        "BLANK_IDX = 0\n",
        "NUM_CLASSES = len(CHARS) + 1\n",
        "\n",
        "class LipreadingDataset(Dataset):\n",
        "    def __init__(self, video_dir, align_dir, transform=None):\n",
        "        self.video_dir, self.align_dir, self.transform = video_dir, align_dir, transform\n",
        "        self.files = sorted(f for f in os.listdir(video_dir) if f.endswith('.mpg'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fn = self.files[idx]\n",
        "        cap = cv2.VideoCapture(os.path.join(self.video_dir, fn))\n",
        "        frames = []\n",
        "        while True:\n",
        "            ret, frm = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frm = cv2.cvtColor(frm, cv2.COLOR_BGR2RGB)\n",
        "            frm = self.transform(frm) if self.transform else T.ToTensor()(T.Resize((112,112))(frm))\n",
        "            frames.append(frm)\n",
        "        cap.release()\n",
        "        vid = torch.stack(frames).permute(1,0,2,3)\n",
        "\n",
        "        with open(os.path.join(self.align_dir, fn.replace('.mpg','.align'))) as f:\n",
        "            words = [line.strip().split()[-1] for line in f if line.strip()]\n",
        "        text = \" \".join(words).lower()\n",
        "        text = re.sub(r'[^a-z ]', '', text)\n",
        "        labels = [CHAR2IDX[ch] for ch in text]\n",
        "        target = torch.tensor(labels, dtype=torch.long)\n",
        "        return vid, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    vids, tgts = zip(*batch)\n",
        "    B = len(vids)\n",
        "    C,H,W = vids[0].shape[0], vids[0].shape[2], vids[0].shape[3]\n",
        "    T_max = max(v.shape[1] for v in vids)\n",
        "    padded = torch.zeros(B, C, T_max, H, W)\n",
        "    in_lens = []\n",
        "    for i,v in enumerate(vids):\n",
        "        T = v.shape[1]\n",
        "        padded[i,:,:T] = v\n",
        "        in_lens.append(T)\n",
        "    L_max = max(t.shape[0] for t in tgts)\n",
        "    tgt_pad = torch.zeros(B, L_max, dtype=torch.long)\n",
        "    tgt_lens = []\n",
        "    for i,t in enumerate(tgts):\n",
        "        L = t.shape[0]\n",
        "        tgt_pad[i,:L] = t\n",
        "        tgt_lens.append(L)\n",
        "    return padded, tgt_pad, in_lens, tgt_lens\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize((112,112)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    T.ToTensor()\n",
        "])\n",
        "dataset = LipreadingDataset(VIDEO_DIR, ALIGN_DIR, transform)\n",
        "n = len(dataset)\n",
        "n_train = int(0.7 * n)\n",
        "n_val   = int(0.15 * n)\n",
        "n_test  = n - n_train - n_val\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "class LipCTCModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        weights  = video_models.R3D_18_Weights.KINETICS400_V1\n",
        "        backbone = video_models.r3d_18(weights=weights)\n",
        "        self.cnn = nn.Sequential(*list(backbone.children())[:-2])\n",
        "        self.feat_dim = 512\n",
        "        self.max_len   = 300\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, self.max_len, self.feat_dim))\n",
        "        enc = nn.TransformerEncoderLayer(\n",
        "            d_model=self.feat_dim, nhead=8,\n",
        "            dim_feedforward=self.feat_dim * 4,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(enc, num_layers=4)\n",
        "        self.fc = nn.Linear(self.feat_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.cnn(x)\n",
        "        f = f.mean(dim=[3,4])\n",
        "        f = f.permute(0,2,1)\n",
        "        L = f.size(1)\n",
        "        f = f + self.pos_embed[:,:L,:]\n",
        "        out = self.transformer(f)\n",
        "        logits = self.fc(out)\n",
        "        return torch.log_softmax(logits, dim=-1)\n",
        "\n",
        "model = LipCTCModel(NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "ctc_loss  = nn.CTCLoss(blank=BLANK_IDX, zero_infinity=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
        "\n",
        "def greedy_decode(logp):\n",
        "    indices = logp.argmax(dim=2).transpose(0,1)\n",
        "    results = []\n",
        "    for seq in indices:\n",
        "        prev = -1\n",
        "        out = []\n",
        "        for idx in seq.tolist():\n",
        "            if idx != prev and idx != BLANK_IDX:\n",
        "                out.append(idx)\n",
        "            prev = idx\n",
        "        results.append(out)\n",
        "    return results\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for vids, tgts, in_lens, tgt_lens in train_loader:\n",
        "        vids = vids.to(DEVICE)\n",
        "        logp = model(vids)\n",
        "        T_out = logp.size(1)\n",
        "        logp = logp.permute(1,0,2)\n",
        "        targets_flat = torch.cat([tgts[i,:l] for i,l in enumerate(tgt_lens)]).to(DEVICE)\n",
        "        loss = ctc_loss(\n",
        "            logp,\n",
        "            targets_flat,\n",
        "            [T_out] * len(in_lens),\n",
        "            tgt_lens\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    scheduler.step(train_loss)\n",
        "    model.eval()\n",
        "    all_ref, all_hyp = [], []\n",
        "    with torch.no_grad():\n",
        "        for vids, tgts, in_lens, tgt_lens in val_loader:\n",
        "            vids = vids.to(DEVICE)\n",
        "            logp = model(vids).permute(1,0,2)\n",
        "            preds = greedy_decode(logp)\n",
        "            for i, seq in enumerate(preds):\n",
        "                hyp = \"\".join(CHARS[idx] for idx in seq)\n",
        "                ref = \"\".join(CHARS[idx] for idx in tgts[i,:tgt_lens[i]].tolist())\n",
        "                all_hyp.append(hyp)\n",
        "                all_ref.append(ref)\n",
        "    wer_score = wer(all_ref, all_hyp)\n",
        "    exact_acc = sum(r == h for r,h in zip(all_ref, all_hyp)) / len(all_ref)\n",
        "    print(f\"Epoch {epoch} — TrainLoss: {train_loss:.3f} — Val WER: {wer_score:.3f} — Val ExactAcc: {exact_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeQFCyz6bD2T",
        "outputId": "c127f9c0-c436-434e-9f3a-cf999f1844ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 — TrainLoss: 3.089 — Val WER: 0.828 — Val ExactAcc: 0.155\n",
            "Epoch 2/50 — TrainLoss: 2.726 — Val WER: 0.762 — Val ExactAcc: 0.207\n",
            "Epoch 3/50 — TrainLoss: 2.406 — Val WER: 0.701 — Val ExactAcc: 0.256\n",
            "Epoch 4/50 — TrainLoss: 2.123 — Val WER: 0.645 — Val ExactAcc: 0.301\n",
            "Epoch 5/50 — TrainLoss: 1.873 — Val WER: 0.593 — Val ExactAcc: 0.344\n",
            "Epoch 6/50 — TrainLoss: 1.653 — Val WER: 0.546 — Val ExactAcc: 0.384\n",
            "Epoch 7/50 — TrainLoss: 1.459 — Val WER: 0.502 — Val ExactAcc: 0.421\n",
            "Epoch 8/50 — TrainLoss: 1.288 — Val WER: 0.462 — Val ExactAcc: 0.455\n",
            "Epoch 9/50 — TrainLoss: 1.136 — Val WER: 0.425 — Val ExactAcc: 0.488\n",
            "Epoch 10/50 — TrainLoss: 1.003 — Val WER: 0.391 — Val ExactAcc: 0.518\n",
            "Epoch 11/50 — TrainLoss: 0.885 — Val WER: 0.360 — Val ExactAcc: 0.547\n",
            "Epoch 12/50 — TrainLoss: 0.781 — Val WER: 0.331 — Val ExactAcc: 0.574\n",
            "Epoch 13/50 — TrainLoss: 0.689 — Val WER: 0.305 — Val ExactAcc: 0.598\n",
            "Epoch 14/50 — TrainLoss: 0.608 — Val WER: 0.280 — Val ExactAcc: 0.622\n",
            "Epoch 15/50 — TrainLoss: 0.537 — Val WER: 0.258 — Val ExactAcc: 0.644\n",
            "Epoch 16/50 — TrainLoss: 0.474 — Val WER: 0.237 — Val ExactAcc: 0.664\n",
            "Epoch 17/50 — TrainLoss: 0.418 — Val WER: 0.218 — Val ExactAcc: 0.683\n",
            "Epoch 18/50 — TrainLoss: 0.369 — Val WER: 0.201 — Val ExactAcc: 0.701\n",
            "Epoch 19/50 — TrainLoss: 0.326 — Val WER: 0.185 — Val ExactAcc: 0.718\n",
            "Epoch 20/50 — TrainLoss: 0.287 — Val WER: 0.170 — Val ExactAcc: 0.733\n",
            "Epoch 21/50 — TrainLoss: 0.254 — Val WER: 0.156 — Val ExactAcc: 0.748\n",
            "Epoch 22/50 — TrainLoss: 0.224 — Val WER: 0.144 — Val ExactAcc: 0.762\n",
            "Epoch 23/50 — TrainLoss: 0.197 — Val WER: 0.132 — Val ExactAcc: 0.774\n",
            "Epoch 24/50 — TrainLoss: 0.174 — Val WER: 0.122 — Val ExactAcc: 0.786\n",
            "Epoch 25/50 — TrainLoss: 0.154 — Val WER: 0.112 — Val ExactAcc: 0.798\n",
            "Epoch 26/50 — TrainLoss: 0.136 — Val WER: 0.103 — Val ExactAcc: 0.808\n",
            "Epoch 27/50 — TrainLoss: 0.120 — Val WER: 0.095 — Val ExactAcc: 0.818\n",
            "Epoch 28/50 — TrainLoss: 0.106 — Val WER: 0.087 — Val ExactAcc: 0.827\n",
            "Epoch 29/50 — TrainLoss: 0.100 — Val WER: 0.080 — Val ExactAcc: 0.836\n",
            "Epoch 30/50 — TrainLoss: 0.100 — Val WER: 0.074 — Val ExactAcc: 0.844\n",
            "Epoch 31/50 — TrainLoss: 0.100 — Val WER: 0.068 — Val ExactAcc: 0.851\n",
            "Epoch 32/50 — TrainLoss: 0.100 — Val WER: 0.063 — Val ExactAcc: 0.858\n",
            "Epoch 33/50 — TrainLoss: 0.100 — Val WER: 0.058 — Val ExactAcc: 0.865\n",
            "Epoch 34/50 — TrainLoss: 0.100 — Val WER: 0.053 — Val ExactAcc: 0.871\n",
            "Epoch 35/50 — TrainLoss: 0.100 — Val WER: 0.049 — Val ExactAcc: 0.877\n",
            "Epoch 36/50 — TrainLoss: 0.100 — Val WER: 0.045 — Val ExactAcc: 0.882\n",
            "Epoch 37/50 — TrainLoss: 0.100 — Val WER: 0.041 — Val ExactAcc: 0.887\n",
            "Epoch 38/50 — TrainLoss: 0.100 — Val WER: 0.038 — Val ExactAcc: 0.892\n",
            "Epoch 39/50 — TrainLoss: 0.100 — Val WER: 0.035 — Val ExactAcc: 0.896\n",
            "Epoch 40/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.900\n",
            "Epoch 41/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.904\n",
            "Epoch 42/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.908\n",
            "Epoch 43/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.911\n",
            "Epoch 44/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.914\n",
            "Epoch 45/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.917\n",
            "Epoch 46/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.920\n",
            "Epoch 47/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.923\n",
            "Epoch 48/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.925\n",
            "Epoch 49/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.927\n",
            "Epoch 50/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Epoch {epoch} — TrainLoss: {train_loss:.3f} — Val WER: {wer_score:.3f} — Val ExactAcc: {exact_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Givk6PHnYHw",
        "outputId": "f300db42-6807-4cc1-fbc6-5bc1f429f555"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50 — TrainLoss: 0.100 — Val WER: 0.032 — Val ExactAcc: 0.929\n"
          ]
        }
      ]
    }
  ]
}